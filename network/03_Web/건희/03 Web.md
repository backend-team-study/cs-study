# 03 Web

# Web이란

Web(World Wide Web)이란 인터넷 연결된 사용자들이 서로의 정보를 공유할 수 있는 공간이다. HTML 언어를 사용하여 작성된 하이퍼텍스트 문서를 웹 페이지라고 부른다.

## Web Server 와 Web Application Server

### 웹 서버

- “웹 브라우저 클라이언트로부터 HTTP 요청을 받아들이고 HTML 문서와 같은 정적 컨텐츠를 제공하는 서버”
- 웹 서버가 동적 컨텐츠를 요청 받으면 WAS에게 해당 요청을 넘겨주고, WAS에서 처리한 결과를 클라이언트에게 전달해주는 역할도 한다.
- Apache에서는 CGI (Common Gateway Interface)를 제공하여 웹 서버와 외부 프로그램 사이에서 정보를 주고 받을 수 있다. (PHP, Perl, Python 에서만 가능하며 Java에서는 불가능)
- ex) Apache, Nginx, IIS 등

### 웹 애플리케이션 서버

- “인터넷 상에서 HTTP 프로토콜을 이용하여 사용자 컴퓨터나 장치에 애플리케이션을 수행해주는 미들웨어 (소프트웨어 엔진)으로 볼 수 있다.”
- 웹 애플리케이션 서버는 동적 서버 컨텐츠를 수행하는 것으로 일반적인 웹 서버와 구별되며, 주로 데이터베이스 서버와 같이 수행된다.
- ex) Tomcat, WebSphere, Jeus 등

### 웹 서버와 웹 애플리케이션의 효율적 사용

웹 서버가 할 수 있는 일을 WAS 역시 처리가 가능한데 왜 굳이 같이 사용하는 것일까?

- WAS만 사용하다가 WAS에 장애가 발생하여 다운 될 경우, 에러에 대한 정적 페이지를 뿌려줄 수도 없게 된다.
- WAS는 DB 조회 및 다양한 로직을 처리하는 데 집중해야 한다. 따라서 단순한 정적 컨텐츠는 웹 서버에게 맡기며 기능을 분리해 서버 부하를 방지해줘야 한다.

> Tomcat의 경우 풀네임이 Apache Tomcat인 만큼 WAS 이지만 Apache의 기능을 추가하여 정적 리소스를 따로 처리할 수 있는 기능을 갖추고 있다.

## Apache 와 Nginx

### Apache

아파치 웹 서버는 사용자의 HTTP 요청이 올 때마다 프로레스나 스레드를 새로 만든다. 크게 두 가지 방식으로 동작하게 된다.

1. Prefork MPM (Mulit Processing Module) 방식

https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/cbFKg7/btrr1NgUUcP/EsQYlUXqWvl6zdYtJpahC1/img.png

- HTTP 연결 요청이 올 때마다 프로세스를 매번 복제하여 프로세스에서 싱글 스레드로 해당 요청을 처리한다.
- 사용자 요청 수 = 프로세스 수

1. Worker MPM (Multi Thread) 방식

https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/bmzK3M/btrr1NaasvA/my4N0J0Hc0haYp8rVYfjP0/img.png

- 한 개의 프로세스가 여러 스레드를 생성하여 해당 HTTP 요청을 처리하므로 Prefork 방식보다 메모리 소모가 적다. 하지만 멀티 스레드 방식은 `컨텍스트 스위칭` 비용이 발생하는 단점이 있다. 스레드를 분배하기 위해 사용되는 CPU 스케줄링에 대한 연산 작업과 쓰레드 간의 전환을 위해 쓰레드의 상태 (컨텍스트)를 저장해두기 위한 CPU 연산 작업으로 쓰레드가 많아질 수록 성능 저하가 발생한다.

### Nginx

Apache 에서는 사용자의 요청 수가 많아질 수록 성능이 저하되어 결국에는 요청을 처리할 수 없게 되는 C10K 문제가 있었는데, 이러한 한계를 극복하고자 러시아 개발자가 만든 `비동기 이벤트` 기반의 웹 서버이다.

Nginx에서는 커넥션 생성 및 커넥션 제거, 그리고 새로운 요청을 처리하는 것을 이벤트라고 부른다. 이 이벤트들은 OS 커널이 `큐` 형식으로 worker 프로세스에게 전달해주고, 이벤트가 큐에 담긴 상태에서 worker 프로세스가 처리할 때까지 비동기 방식으로 대기한다. 그리고 워커 프로세스는 하나의 스레드로 이벤트를 꺼내서 처리해 나간다.

만약 큐에 있는 요청 중 하나가 시간이 오래걸리는 작업이라면, 별도의 쓰레드 풀을 만들어 작업을 위임하고 worker 프로세스는 다른 요청을 처리하러 간다.

https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https://blog.kakaocdn.net/dn/QRh8u/btrsfWbzQPo/MRnkr4DxlZddNd08gukih0/img.png

!https://user-images.githubusercontent.com/37354145/140635218-c73ab34d-41da-42a5-afaa-bcb9a00fcbe0.png

## SSL Offloading

애플리케이션 서버에서 TLS 핸드쉐이크를 수행하지 않고 트래픽이 전달되기 전 로드밸런서에서 SSL 인증서를 관리하고 TLS 핸드쉐이크를 수행하는 것을 말한다. 아마존 웹 서비스의 ELB 유형 중 NLB (L4)와 ALB(L7)는 인증서를 등록하고 클라이언트와 TLS 핸드쉐이크를 수행하여 트래픽이 EC2 인스턴스 또는 컨테이너로 전달시키는 TLS 오프로딩 기능을 지원한다.

또한, 백엔드 서버가 여러 대일 경우 모든 서버에 SSL을 적용하기 보다 로드밸런서 혹은 웹 서버에만 인증서를 구매하고 설치하여 SSL Offloading을 해주는 편이 시간과 비용 모두 절약이 가능하다!

(서버가 인증 책임으로부터 자유로워짐)

## Reverse Proxy

### 프록시란?

프록시 서버는 클라이언트가 자신을 통해서 다른 네트워크 서비스에 간접적으로 접속할 수 있게 해주는 컴퓨터 시스템이나 응용 프로그램을 가리킨다.

### Forward Proxy & Reverse Proxy

- 포워드

같은 내부망에 존재하는 클라이언트의 요청을 받아 인터넷을 통해 외부 서버에서 데이터를 가져와 클라이언트에게 응답해준다.

즉, 클라이언트가 서버에 접근하고자 할 때, 클라이언트는 타겟 서버의 주소를 포워드 프록시에 전달하여 포워드 프록시가 인터넷으로 요청된 내용을 가져오는 방식이다.

보통 정부, 학교, 기업 등과 같은 기관에 속한 사람들의 인터넷 사용을 제한하기 위해 방화벽을 사용하는데, 포워드 프록시 서버도 제한을 위해 사용된다고 보면 된다.

포워드 프록시를 통과할 때 클라이언트의 요청이 암호화되어 클라이언트를 감춰 주는 보안 효과도 내준다.

- 리버스

리버스 프록시는 웹 서비스에 접근할 때 웹 서버에 직접 요청을 보내는 것이 아닌, 프록시 서버로 요청을 보내게 되고 프록시가 배후의 서버로부터 데이터를 가져오는 방식이다.

본래 서버의 IP 주소를 노출시키지 않을 수 있기 때문에 보안적으로 유리하며, 포워드 프록시와 마찬가지로 요청에 대한 응답을 캐싱하여 서버로 요청을 보내지 않고 프록시 서버에서 캐싱된 응답을 내려줄 수 있다.

## Load Balancing

부하분산 또는 로드 밸런싱은 서버에 가해지는 부하를 분산해주는 장치 또는 기술이다.

사업의 규모가 확장되고, 클라이언트의 수가 늘어나게 되면 기존 서버만으로는 정상적인 서비스가 불가능하게 되는데, 이때 우리는 Scale up과 Scale out 전략을 선택하여 대처할 수 있다. Scale Out을 선택하게 되는 경우 여러 대의 서버로 트래픽을 균등하게 분산해줄 필요가 생기게 되고, 이러한 작업을 수행하는 것이 로드 밸런싱이다.

### 로드 밸런싱의 기본 기능

1. Health Check 상태 확인

서버들에 대한 주기적인 헬스 채크를 통해 서버들의 장애 여부를 판단하여, 정상 작동 중인 서버로만 트래픽을 보낸다.

- L3 체크 : ICMP (Internet Control Message Protocol 패킷 전송 실패에 대한 메시지 (IP 계층에서 동작) 를 이용하여 IP 주소가 통신 가능한 상태인지를 확인
- L4 체크 : TCP의 3 Way Handshake를 통해 각 포트 상태를 체크
- L7 체크 : 실제 웹 페이지에 통신을 시도하여 이상 유무를 파악

1. NAT (Network Address Translation)

- 내부 네트워크에서 사용하는 사설 IP 주소와 로드밸런서 외부의 공인 IP 주소 간의 변환 역할
- 로드밸런싱 관점에서는 여러 개의 호스트가 하나의 공인 IP 주소를 통해 접속하는 것이 주 목적
- SNAT, DNAT, DSR (이 세 가지도 알아볼 것)

### 로드 밸런싱 알고리즘

1. 라운드 로빈

- 서버로 들어온 요청을 순서대로 돌아가며 배정하는 방식
- 클라이언트의 요청을 순서대로 분배하기 때문에 서버들이 `동일한 스펙`을 갖고 있고, 서버와의 연결이 오래 지속되지 않는 경우에 활용하기 적합.

1. 가중 라운드 로빈

- 각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분.
- 주로 `서버의 트래픽 처리 능력이 상이한 경우` 사용됨.

1. IP 해시 방식

- 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식
- 사용자의 IP를 해싱하여 부하를 분산하기 때문에 사용자가 동일한 서버로 연결되는 것을 보장
- 경로가 보장되며, 접속자 수가 많을 수록 분산 및 효율이 뛰어남. (서브넷 상에서 자신이 사용하는 IP가 항상 고정인 건가?)

1. 최소 연결 방식

- 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 우선적으로 트래픽을 할당
- 연결이 오래 지속되거나, 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합

1. 최소 응답 시간 방식

- 서버의 현재 연결 상태와 응답 시간을 모두 고려하여, 가장 짧은 응답 시간을 보내는 서버로 트래픽을 할당
- 각 서버들의 가용한 리소스와 성능, 처리중인 데이터 양 등이 상이할 경우 적합

## L4 vs L7

로드밸런싱에는 L4와 L7 로드밸런서가 가장 많이 활용되는데, 그 이유는 `L4 로드밸런서부터 포트 정보를 바탕으로 로드를 분산 가능`하기 때문이다. 한 대의 서버에 각기 다른 포트 번호를 부여하여 다수의 서버 프로그램을 운영하는 경우라면 최소 L4 로드밸런서 이상을 사용해야만 하는 것.

### L4 로드밸런서

L4 로드밸런서라는 이름에서 알 수 있듯이 4계층인 TCP 헤더에 담긴 정보를 이해하고 이 정보를 기반으로 동작한다.

***\**\*\*\*\*\*장점\*\*\*\*\*\**\***

- 패킷의 내용을 확인하지 않고 로드를 분산하므로 속도가 빠르고 효율이 높다.
  - L4 로드밸런서는 패킷을 빠르게 전달하기 위해 패킷 내부의 데이터를 처리하지 않는다.
  - TCP/UDP 프로토콜은 패킷 내부의 데이터를 확인할 필요 없이 헤더 정보만으로 패킷을 전달하고 연결을 관리할 수 있다.
- 데이터의 내용을 복호화할 필요가 없기에 안전하다.
- 가격이 저렴하다

***\**\*단점\*\**\***

- 패킷의 내용을 살펴볼 수 없으므로, 섬세한 라우팅이 불가하다.
- Mega Proxy → L4 정보로만 라우팅을 수행하기 때문에 부하에 관련된 정보를 고려하지 않아 특정 서버에 요청이 집중되는 문제가 발생할 수 있다. 같은 IP를 가진 클라이언트에 대해 HTTP 헤더에 서로 다른 쿠키값을 할당하고 L7 로드밸런서를 사용한다면 해결할 수 있다.
- Multiplexing, Keep-alive 사용 불가능 → L4 만으로는 상위 프로토콜의 정보를 활용할 수 없기 때문이다.

### L7 로드밸런서

애플리케이션 계층에서 로드를 분산하기 때문에 HTTP 헤더, 쿠키 등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽을 분산하는 것이 가능하다.

L4 로드밸런서의 기능에 더하여 `패킷의 내용을 확인하고 그 내용에 따라 로드를 특정 서버에 분배하는 것이 가능하다`.

***\**\*\*\*장점\*\*\*\*\****

- 상위 계층에서 로드를 분산하기 때문에 훨씬 더 섬세한 라우팅 가능하다.
- 캐싱 기능을 제공한다.
- 비정상적인 트래픽을 사전에 필터링할 수 있어 서비스 안정성이 높다.

**단점**

- 가격이 비싸다
- 패킷의 내용을 복호화하여야 하므로 더 높은 비용을 지불해야 한다.
- 클라이언트가 로드밸런서와 인증서를 공유해야하기 때문에 공격자가 로드밸런서를 통해 클라이언트의 데이터에 접근할 수 있는 보안상의 위험성이 존재한다.

## Web Cache

만약 클라이언트가 이전에 받은 데이터와 똑같은 데이터를 서버에 재요청을 할 때 똑같은 통신 과정을 거치게 된다면 이 과정은 낭비라고 할 수 있다. 따라서 이러한 낭비를 줄이기 위한 해결책으로 캐시의 개념을 웹 브라우저에 그대로 적용한 것이 Web Cache이다. HTTP에서 제공하는 헤더인 `Cache-Control` 을 통해 관리할 수 있다.

**헤더 값 파라미터 종류**

- max-age : 캐시 유효 시간, 초 단위
- no-cache : 데이터는 캐시해도 되지만, 항상 Origin Server 에 검증후 사용
- no-store : 데이터에 민감한 정보가 포함되어 있어저장 불가 혹은 최대한빨리 삭제
- public : public 캐시(프록시 캐시 서버)에 저장 가능
- private : public 캐시에 저장 불가
- s-maxage : 프록시 캐시 서버에 적용되는
- max-ageAge : Origin Server 의 응답이 프록시 캐시 서버에 머문 시간(sec)
- must-revalidate : 캐시 만료후 최초 조회시 Origin Server 에 검증

캐시가 만료 시간에 도달한 경우 서버로 다시 요청을 보내야 하는데, `비록 캐시 유효 기간이 지났더라도 오랜 기간 변경되지 않아도 되는 데이터`일 경우 다시 요청을 보내는 건 낭비가 될 수 있다. 그래서 더 효율적인 캐시 전략을 위해 웹 브라우저에는 별도의 캐시 검증 로직을 수행하게 된다.

1. Last-Modified 헤더

- 데이터의 최종 수정 시각을 명시한다.
- If-Modified-Since 요청 헤더와 함께 사용한다.
- 클라이언트가 캐시 유효기간이 초과된 데이터를 서버에 요청하는 경우, 이를 기준으로 데이터가 수정되었는지 검증한다. 예를 들어 서버의 데이터 최종 수정 시각이 Last-Modified 보다 이후라면, 데이터가 수정된 것으로 간주하고, 서버의 데이터 최종 수정 시각이 Last-Modified와 같다면 데이터가 수정되지 않은 것으로 간주한다.
- 날짜 기반의 로직을 사용하기 때문에 한계가 있다. A →B 에서 다시 B → A 로 롤백을 하게 되면 데이터는 그대로 A이지만 수정 시각이 다르기 때문에 캐싱처리가 되지 않는다.

1. ETag 헤더

- 특정 버전의 리소스를 식별하는 고유 식별자
- 서버는 파일이 변경될 때마다 새 ETag 값을 생성하고 이전 ETag 값을 변경한다.
- If-None-Math 요청 헤더와 함께 사용된다.
- Last-Modified 헤더의 한계를 극복하기 위한 리소스 검증 헤더 (서버에서 캐시 제어 가능)

## URL, URI, URN

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/240b8a95-4793-40aa-afcd-383fb3e11370/e073cd03-e86a-4099-93a5-770a00a79495/Untitled.png)

- URI - 자원의 식별자 (Identifier)
- URL - 자원의 위치 (Location)
- URN - 자원의 이름 (Name)

### URI (Uniform Resource Identifier)

통합 자원 식별자 → 인터넷에 있는 자원이 어디에 있는지 자원 자체를 식별하는 방법이다.

- Uniform : 리소스를 식별하는 통일된 방식

- Resource : 자원, URI로 식별할 수 있는 모든 것

  여기서 자원은 웹 브라우저의 파일만 뜻하는 게 아니라, 실시간 교통정보 등 우리가 구분할 수 있는 모든 것

- Identifier : 다른 항목과 구분하는데 필요한 정보

- URI의 존재는 인터넷에서 요구되는 기본 조건으로 인터넷 프로토콜에 항상 붙어 다닌다.

- 하위 개념으로 URL, URN이 있다.

예를들어 다음과 같은 홈페이지 링크가 있다고 하자.

```
http://steadies.kr/posts?page=123&id=12
```

여기서 `URL`은 posts의 위치를 표기한 http://steadies.kr/posts 까지이다. 하지만 사용자가 원하는 정보에 도달 하기위해서는 ?page=123&id=12 라는 식별자가 필요한 것이다. 따라서 엄격히 구분하자면 위의 전체 주소는 URI이고, 식별자가 빠진 것을 URL이라고 하는 것이다.

## Rest API

Representational State Transfer API의 약자로, `웹 서비스를 개발하기 위해 사용되는 아키텍처`이다.

REST는 클라이언트와 서버 간의 통신을 위한 규칙과 제약 조건을 정의한다. 이를 통해 클라이언트는 HTTP 프로토콜을 사용하여 서버에 요청을 보내고, 서버는 그에 따른 응답을 제공한다.

1. Uniform (유니폼 인터페이스)

Uri로 지정한 리소스에 대한 조작을 통일되고 한정적인 인터페이스로 수행하는 아키텍처 스타일

1. Stateless (무상태성)

REST는 무상태성 성격을 갖습니다. 다시 말해 작업을 위한 상태정보를 따로 저장하고 관리하지 않습니다. API 서버는 들어오는 요청만을 단순히 처리하면 됩니다. 때문의 서비스의 자유도가 높아지고 서버에서 불필요한 정보를 관리하지 않음으로써 구현이 단순해집니다.

1. Cachealbe (캐시 가능)

HTTP라는 기존 웹 표준을 그대로 사용하기 때문에, 웹에서 사용하는 기존 인프라를 그대로 활용이 가능합니다.

1. Self-descriptiveness (자체 표현 구조)

REST API 메시지만 보고도 이를 쉽게 이해할 수 있는 자체 표현 구조로 되어 있습니다.

1. Client - Server 구조

REST 서버는 API 제공, 클라이언트는 사용자 인증이나 컨텍스트 등을 직접 관리하는 구조로 각각의 역할이 확실히 구분되기 때문에 클라이언트와 서버에서 개발해야 할 내용이 명확해지고 서로간 의존성이 줄어들게 됩니다.

1. 계층형 구조

다중 계층으로 구성될 수 있으며 보안, 로드 밸런싱, 암호화 계층을 추가해 구조상의 유연성을 둘 수 있고 PROXY, 게이트웨이 같은 네트워크 기반의 중간 매체를 사용할 수 있게 합니다.